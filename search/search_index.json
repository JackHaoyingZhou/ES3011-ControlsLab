{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"competition-overview/","text":"Competition Overview Robotics and AI is revolutionizing the what and how we work today and will continue in the future. Today, robots are augmenting the capability of human workers in various industries: logistics, healthcare, agriculture, etc. The PARC Engineers league tasks participants to reimagine how humans can augment the capabilities of intelligent robots in a task of growing prevalence - autonomous parcel delivery. The challenge of the competition is to build software to operate a wheeled mobile robot to complete a delivery task including: navigating through a sidewalk, crossing the road using a crosswalk and navigating in a park to find the drop location. This competition would consist two phases: a simulation phase and a physical robot phase. Simulation Phase In this phase, teams would interact with the delivery robot in simulation (using the Gazebo Robot Simulator). Participants are required to write software to complete three crucial tasks for the operation of a delivery robot: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) Participating teams can download the complete simulation packages (follow this link) and follow the instruction [here] to set up their PCs and complete the tasks. Teams are required to submit their solutions to the competition drive on or before the Phase 1 deadline. Following team evaluations, teams with the best solutions will qualify to compete in Phase 2. Physical Robot Phase In this phase, the qualified teams get a chance to refine and deploy their software on the physical robot to compete on the main competition day. First, a complete simulation of the competition environment would be provided to teams to integrate and their solutions from Phase 1. The task here is to operate the delivery robot to complete a delivery by moving from parcel pickup location to the drop-off location. Once satisfactory results are achieved in simulation, participants would be allowed to test their software on the physical robot virtually by reserving time on our booking calendar [to be provided]. To be allowed to compete on the final competition, teams must submit a report (including videos of their fully functional solution in simulation) and upload their code for review. How to Participate Prospective teams would be required to complete an online application [add link to online form] by providing the following information: Team name and affiliation Team members names Previous experiences with robotics A one-page essay on the role of robotics on the future of work in Africa (uploaded as a PDF) Important Dates Event Date Registration Opens February 5th 2021 Registration Deadline February 19th 2021 Phase 1 Qualification Announcement February 26th 2021 Phase 1 Submission Deadline June 1st 2021 Phase 2 Qualification Announcement June 11th 2021 Phase 2 Submission Deadline July 11th 2021 Final Competition Day July 2021","title":"Competition Overview"},{"location":"competition-overview/#competition_overview","text":"Robotics and AI is revolutionizing the what and how we work today and will continue in the future. Today, robots are augmenting the capability of human workers in various industries: logistics, healthcare, agriculture, etc. The PARC Engineers league tasks participants to reimagine how humans can augment the capabilities of intelligent robots in a task of growing prevalence - autonomous parcel delivery. The challenge of the competition is to build software to operate a wheeled mobile robot to complete a delivery task including: navigating through a sidewalk, crossing the road using a crosswalk and navigating in a park to find the drop location. This competition would consist two phases: a simulation phase and a physical robot phase.","title":"Competition Overview"},{"location":"competition-overview/#simulation_phase","text":"In this phase, teams would interact with the delivery robot in simulation (using the Gazebo Robot Simulator). Participants are required to write software to complete three crucial tasks for the operation of a delivery robot: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) Participating teams can download the complete simulation packages (follow this link) and follow the instruction [here] to set up their PCs and complete the tasks. Teams are required to submit their solutions to the competition drive on or before the Phase 1 deadline. Following team evaluations, teams with the best solutions will qualify to compete in Phase 2.","title":"Simulation Phase"},{"location":"competition-overview/#physical_robot_phase","text":"In this phase, the qualified teams get a chance to refine and deploy their software on the physical robot to compete on the main competition day. First, a complete simulation of the competition environment would be provided to teams to integrate and their solutions from Phase 1. The task here is to operate the delivery robot to complete a delivery by moving from parcel pickup location to the drop-off location. Once satisfactory results are achieved in simulation, participants would be allowed to test their software on the physical robot virtually by reserving time on our booking calendar [to be provided]. To be allowed to compete on the final competition, teams must submit a report (including videos of their fully functional solution in simulation) and upload their code for review.","title":"Physical Robot Phase"},{"location":"competition-overview/#how_to_participate","text":"Prospective teams would be required to complete an online application [add link to online form] by providing the following information: Team name and affiliation Team members names Previous experiences with robotics A one-page essay on the role of robotics on the future of work in Africa (uploaded as a PDF)","title":"How to Participate"},{"location":"competition-overview/#important_dates","text":"Event Date Registration Opens February 5th 2021 Registration Deadline February 19th 2021 Phase 1 Qualification Announcement February 26th 2021 Phase 1 Submission Deadline June 1st 2021 Phase 2 Qualification Announcement June 11th 2021 Phase 2 Submission Deadline July 11th 2021 Final Competition Day July 2021","title":"Important Dates"},{"location":"getting-started/setting-up-your-pc/","text":"How to setup the Computer This guide helps you setup your computer for running the competition environment locally and developing the code. You can use local Computer/Laptop or Virtual Machine inside your computer or any cloud platform like Google GCP , Amazon AWS , Microsoft Azure , Digital Ocean , etc (All Cloud providers have some free trial plan which you can make use of). System requirements The competition setup needs to be run on Ubuntu , a flavor of Linux . You will need a computer that has: A dedicated GPU , Nvidia cards tend to work well in Ubuntu A CPU that is at least an Intel i5, or equivalent, At least 4GB of free disk space, At least 8GB of RAM, Ubuntu Xenial installed. Operating System If not already installed, Install Ubuntu Bionic (18.04) on the system by following this guide . Note It is highly recommended to install Bionic (18.04) version of Ubuntu due to ROS (Melodic) dependency. Installing ROS You need to install ROS Melodic by following this guide and install ros-melodic-desktop-full in the step 1.4 of the guide.","title":"Setting up your PC"},{"location":"getting-started/setting-up-your-pc/#how_to_setup_the_computer","text":"This guide helps you setup your computer for running the competition environment locally and developing the code. You can use local Computer/Laptop or Virtual Machine inside your computer or any cloud platform like Google GCP , Amazon AWS , Microsoft Azure , Digital Ocean , etc (All Cloud providers have some free trial plan which you can make use of).","title":"How to setup the Computer"},{"location":"getting-started/setting-up-your-pc/#system_requirements","text":"The competition setup needs to be run on Ubuntu , a flavor of Linux . You will need a computer that has: A dedicated GPU , Nvidia cards tend to work well in Ubuntu A CPU that is at least an Intel i5, or equivalent, At least 4GB of free disk space, At least 8GB of RAM, Ubuntu Xenial installed.","title":"System requirements"},{"location":"getting-started/setting-up-your-pc/#operating_system","text":"If not already installed, Install Ubuntu Bionic (18.04) on the system by following this guide . Note It is highly recommended to install Bionic (18.04) version of Ubuntu due to ROS (Melodic) dependency.","title":"Operating System"},{"location":"getting-started/setting-up-your-pc/#installing_ros","text":"You need to install ROS Melodic by following this guide and install ros-melodic-desktop-full in the step 1.4 of the guide.","title":"Installing ROS"},{"location":"getting-started/setting-up-your-workspace/","text":"How to set up your workspace In this tutorial, you will set your set up a directory on your ROS-enabled PC as your workspace for development and install the competition ROS packages. Please follow the instructions below carefully. Note This can ONLY be completed after you have set up your PC (by following the previous tutorial) Setup ROS workspace Open a new terminal on your PC, then copy and paste the following one line at a time: mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_init_workspace Clone the repository In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws/src git clone --recurse-submodules https://github.com/PARC-Robotics/parc-robot.git Install dependencies In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws sudo apt update rosdep install --from-paths ./src --ignore-src -y Compile packages cd ~/catkin_ws catkin_make source ~/catkin_ws/devel/setup.bash Set up ROS environment To set the environment every time you launch a new terminal, following this command: echo source ~/catkin_ws/devel/setup.bash ~/.bashrc source ~/.bashrc As you develop, it is good to set the environment variables whenever you run a catkin_make command to compile changes to your packages. You can do that by: source ~/catkin_ws/devel/setup.bash Test installation If you completed the preceding tasks successfully, you should be able to run this ROS launch command and see the Gazebo simulator and RViz simulator open with the following display: roslaunch parc-robot robot.launch","title":"Setting up your Workspace"},{"location":"getting-started/setting-up-your-workspace/#how_to_set_up_your_workspace","text":"In this tutorial, you will set your set up a directory on your ROS-enabled PC as your workspace for development and install the competition ROS packages. Please follow the instructions below carefully. Note This can ONLY be completed after you have set up your PC (by following the previous tutorial)","title":"How to set up your workspace"},{"location":"getting-started/setting-up-your-workspace/#setup_ros_workspace","text":"Open a new terminal on your PC, then copy and paste the following one line at a time: mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_init_workspace","title":"Setup ROS workspace"},{"location":"getting-started/setting-up-your-workspace/#clone_the_repository","text":"In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws/src git clone --recurse-submodules https://github.com/PARC-Robotics/parc-robot.git","title":"Clone the repository"},{"location":"getting-started/setting-up-your-workspace/#install_dependencies","text":"In the same terminal (or in a new one), copy and paste the following: cd ~/catkin_ws sudo apt update rosdep install --from-paths ./src --ignore-src -y","title":"Install dependencies"},{"location":"getting-started/setting-up-your-workspace/#compile_packages","text":"cd ~/catkin_ws catkin_make source ~/catkin_ws/devel/setup.bash","title":"Compile packages"},{"location":"getting-started/setting-up-your-workspace/#set_up_ros_environment","text":"To set the environment every time you launch a new terminal, following this command: echo source ~/catkin_ws/devel/setup.bash ~/.bashrc source ~/.bashrc As you develop, it is good to set the environment variables whenever you run a catkin_make command to compile changes to your packages. You can do that by: source ~/catkin_ws/devel/setup.bash","title":"Set up ROS environment"},{"location":"getting-started/setting-up-your-workspace/#test_installation","text":"If you completed the preceding tasks successfully, you should be able to run this ROS launch command and see the Gazebo simulator and RViz simulator open with the following display: roslaunch parc-robot robot.launch","title":"Test installation"},{"location":"phase1-instructions/","text":"Phase 1: Simulation In this simulation-only phase, teams would work on providing solutions to three (3) fundamental tasks of a delivery robot which are: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) The simulation platform to be used in this phase is the Gazebo Simulator . Teams are required to develop, test and submit software to successfully complete these tasks autonomously. This phase will evaluate the teams' capabilities to successfully complete these fundamental tasks required to compete in phase 2 (on the physical robot). Teams are provided with the delivery robot ROS packages and Gazebo environment models to enable them develop and test their solutions (see GitHub Repository ). Each task is designed as stand-alone, not depending on other task functionalities, hence, we request teams to complete the tasks separately. The tasks would be evaluated individually and the total team score for this phase would be the sum of individual task scores. Task 1: Sidewalk following Delivery robots need to be able to navigate safely through street sidewalks as they move from pick up to drop off locations. In this task, we have simplified the sidewalk following problem by adding lanes to the sidewalk. Hence, teams are required to develop software to navigate the robot within the lanes from start to end position. Bear in mind that along with lane following, the robot would be required to avoid obstacles which may lie in its path. Task 1 Goal: The goal of this task is to autonomously control the delivery robot from the start position (initial spawned location) to a goal location on the side walk (to be specified). To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details]. Task Guidelines Note Make sure you have completed the Getting Started Tutorials before starting the tasks. Run the following launch file to bring up the delivery robot in the world in a new terminal roslaunch parc_engineers task1.launch You should see the display below in Gazebo. To the right, there's the robot with the visible LiDAR rays (blue rays) and to the left is the orange-red sphere which represents the goal location . The two locations (robot initial position and goal location) can be set dynamically by passing arguments in the roslaunch command: For updating robot initial position: roslaunch parc_engineers task1.launch robot_x:-30.43 robot_y:-5.17 robot_yaw:1.57 For updating goal location: roslaunch parc_engineers task1.launch goal_x:-12.28 goal_y:2.54 You need to create a new launch file which runs ALL the code you need in your solution. Name this launch file: task1_solution.launch . While developing, we recommend you play around with different start and goal positions to ensure your solution is robust. The time-limit to complete this task is 5 minutes (300 secs) . Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the robot initial position, goal location and locations of obstacles (postbox, fire hydrant, etc.) would be randomized. Scoring The score for this task would be determined using the following metrics: Out-of-lane distance penalty Final distance from goal location (i.e. euclidean distance from goal position at time-limit) No. of collisions penalty Completion time Task 2: Traffic sign detection and recognition Road crossing is inevitable for delivery robots as they navigate our streets to complete their delivery task. The task of road crossing is tricky even for humans to complete safely. A major component of the task is monitoring the traffic sign to ensure you comply with it. In this task, you are required to perform traffic sign detection and recognition. We have included a traffic sign with two states (RED and GREEN). Teams are required to develop software to use the on-board camera to detect and recognise the state of the traffic sign. Task 2 Goal: The goal of this task is to perform safe road crossing by detecting and recognising the state of the traffic sign and crossing only when the state is GREEN (GO). Task Guidelines Note Make sure you have completed the Getting Started Tutorials before starting the tasks. Run the following launch file to bring up the delivery robot in the world in a new terminal roslaunch parc_engineers task2.launch You should see the display below in Gazebo. The traffic sign is initially set to RED and would change to GREEN after the start_delay duration is complete. While developing, we recommend you play around with different values for the start_delay duration by passing an argument as follows: roslaunch parc_engineers task2.launch start_delay:=20 The time duration from GREEN to RED is set to 20 secs . This means that you have ~20 secs to cross the road and reach the goal (x=-2.3, y=11.1) after the traffic sign goes green. If the robot is still on the cross walk (i.e. its X position is less than -2.1), the crossing would be considered as failed. Note Ensure you DO NOT provide a solution with hard-coded move commands for the robot based on a particular start_delay value because in evaluation, the start_delay value would be randomized. Also, NO hacks for monitoring the state of the traffic sign (such as checking any ROS topics) would be allowed. If it is found out, you will receive a ZERO score for this task. Scoring The score for this task would be determined using the following metrics: Reaction time Goal completion i.e. has the robot reached the other side of road by the termination of green signal? Wrong crossing (binary) Completion time Task 3: Go-to-goal navigation Task Guidelines Goal: Implement software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion to move from the start position towards to drop off which is in front of the person standing in the park. Step 1: Review the \"Task 3\" folder in the Github repository. Step 2: Complete the [Setting up your PC] and [Setting up workspace] steps (if you have not already done so). Step 3: Run the following launch file to bring up the robot in the designated world in a new terminal roslaunch our-robot-package-name task3.launch Scoring The score for this task would be determined using the following metrics: No. of collisions penalty Final distance from goal (set time limit) Completion time What to Submit Teams would submit a zipped folder containing the following: Complete catkin workspace src folder containing all the installed packages used to complete the task. A README file (either .txt, .md, or .pdf) with the following information: List all the packages installed and used in your solution. Provide commands required to run your solution. This should be: Task 1: roslaunch your-package-name task1_solution.launch Task 2: roslaunch your-package-name task2_solution.launch Task 3: roslaunch your-package-name task3_solution.launch NOTE: Please ensure you include all the packages (dependencies) used in your solution in your package's \"package.xml\" file [see guide]. The zipped folder should be uploaded using this solution submission form .","title":"Phase 1: Simulation"},{"location":"phase1-instructions/#phase_1_simulation","text":"In this simulation-only phase, teams would work on providing solutions to three (3) fundamental tasks of a delivery robot which are: Sidewalk following (with obstacle avoidance) Traffic sign detection and recognition Go-to-goal navigation (with obstacle avoidance) The simulation platform to be used in this phase is the Gazebo Simulator . Teams are required to develop, test and submit software to successfully complete these tasks autonomously. This phase will evaluate the teams' capabilities to successfully complete these fundamental tasks required to compete in phase 2 (on the physical robot). Teams are provided with the delivery robot ROS packages and Gazebo environment models to enable them develop and test their solutions (see GitHub Repository ). Each task is designed as stand-alone, not depending on other task functionalities, hence, we request teams to complete the tasks separately. The tasks would be evaluated individually and the total team score for this phase would be the sum of individual task scores.","title":"Phase 1: Simulation"},{"location":"phase1-instructions/#task_1_sidewalk_following","text":"Delivery robots need to be able to navigate safely through street sidewalks as they move from pick up to drop off locations. In this task, we have simplified the sidewalk following problem by adding lanes to the sidewalk. Hence, teams are required to develop software to navigate the robot within the lanes from start to end position. Bear in mind that along with lane following, the robot would be required to avoid obstacles which may lie in its path. Task 1 Goal: The goal of this task is to autonomously control the delivery robot from the start position (initial spawned location) to a goal location on the side walk (to be specified). To do this, you need to develop software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion [see here for details].","title":"Task 1: Sidewalk following"},{"location":"phase1-instructions/#task_guidelines","text":"Note Make sure you have completed the Getting Started Tutorials before starting the tasks. Run the following launch file to bring up the delivery robot in the world in a new terminal roslaunch parc_engineers task1.launch You should see the display below in Gazebo. To the right, there's the robot with the visible LiDAR rays (blue rays) and to the left is the orange-red sphere which represents the goal location . The two locations (robot initial position and goal location) can be set dynamically by passing arguments in the roslaunch command: For updating robot initial position: roslaunch parc_engineers task1.launch robot_x:-30.43 robot_y:-5.17 robot_yaw:1.57 For updating goal location: roslaunch parc_engineers task1.launch goal_x:-12.28 goal_y:2.54 You need to create a new launch file which runs ALL the code you need in your solution. Name this launch file: task1_solution.launch . While developing, we recommend you play around with different start and goal positions to ensure your solution is robust. The time-limit to complete this task is 5 minutes (300 secs) . Note Ensure you DO NOT provide a solution with hard-coded positions for the robot to move to or hard-coded obstacle positions because in evaluation, the robot initial position, goal location and locations of obstacles (postbox, fire hydrant, etc.) would be randomized.","title":"Task Guidelines"},{"location":"phase1-instructions/#scoring","text":"The score for this task would be determined using the following metrics: Out-of-lane distance penalty Final distance from goal location (i.e. euclidean distance from goal position at time-limit) No. of collisions penalty Completion time","title":"Scoring"},{"location":"phase1-instructions/#task_2_traffic_sign_detection_and_recognition","text":"Road crossing is inevitable for delivery robots as they navigate our streets to complete their delivery task. The task of road crossing is tricky even for humans to complete safely. A major component of the task is monitoring the traffic sign to ensure you comply with it. In this task, you are required to perform traffic sign detection and recognition. We have included a traffic sign with two states (RED and GREEN). Teams are required to develop software to use the on-board camera to detect and recognise the state of the traffic sign. Task 2 Goal: The goal of this task is to perform safe road crossing by detecting and recognising the state of the traffic sign and crossing only when the state is GREEN (GO).","title":"Task 2: Traffic sign detection and recognition"},{"location":"phase1-instructions/#task_guidelines_1","text":"Note Make sure you have completed the Getting Started Tutorials before starting the tasks. Run the following launch file to bring up the delivery robot in the world in a new terminal roslaunch parc_engineers task2.launch You should see the display below in Gazebo. The traffic sign is initially set to RED and would change to GREEN after the start_delay duration is complete. While developing, we recommend you play around with different values for the start_delay duration by passing an argument as follows: roslaunch parc_engineers task2.launch start_delay:=20 The time duration from GREEN to RED is set to 20 secs . This means that you have ~20 secs to cross the road and reach the goal (x=-2.3, y=11.1) after the traffic sign goes green. If the robot is still on the cross walk (i.e. its X position is less than -2.1), the crossing would be considered as failed. Note Ensure you DO NOT provide a solution with hard-coded move commands for the robot based on a particular start_delay value because in evaluation, the start_delay value would be randomized. Also, NO hacks for monitoring the state of the traffic sign (such as checking any ROS topics) would be allowed. If it is found out, you will receive a ZERO score for this task.","title":"Task Guidelines"},{"location":"phase1-instructions/#scoring_1","text":"The score for this task would be determined using the following metrics: Reaction time Goal completion i.e. has the robot reached the other side of road by the termination of green signal? Wrong crossing (binary) Completion time","title":"Scoring"},{"location":"phase1-instructions/#task_3_go-to-goal_navigation","text":"","title":"Task 3: Go-to-goal navigation"},{"location":"phase1-instructions/#task_guidelines_2","text":"Goal: Implement software which processes sensory information from the robots sensors (camera and LiDAR) and generates velocity commands to control the robot's motion to move from the start position towards to drop off which is in front of the person standing in the park. Step 1: Review the \"Task 3\" folder in the Github repository. Step 2: Complete the [Setting up your PC] and [Setting up workspace] steps (if you have not already done so). Step 3: Run the following launch file to bring up the robot in the designated world in a new terminal roslaunch our-robot-package-name task3.launch","title":"Task Guidelines"},{"location":"phase1-instructions/#scoring_2","text":"The score for this task would be determined using the following metrics: No. of collisions penalty Final distance from goal (set time limit) Completion time","title":"Scoring"},{"location":"phase1-instructions/#what_to_submit","text":"Teams would submit a zipped folder containing the following: Complete catkin workspace src folder containing all the installed packages used to complete the task. A README file (either .txt, .md, or .pdf) with the following information: List all the packages installed and used in your solution. Provide commands required to run your solution. This should be: Task 1: roslaunch your-package-name task1_solution.launch Task 2: roslaunch your-package-name task2_solution.launch Task 3: roslaunch your-package-name task3_solution.launch NOTE: Please ensure you include all the packages (dependencies) used in your solution in your package's \"package.xml\" file [see guide]. The zipped folder should be uploaded using this solution submission form .","title":"What to Submit"},{"location":"phase2-instructions/","text":"Phase 2: Physical Robot","title":"Phase 2: Physical Robot"},{"location":"phase2-instructions/#phase_2_physical_robot","text":"","title":"Phase 2: Physical Robot"}]}